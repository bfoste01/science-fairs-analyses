---
title: "EFA Analyses of the Science Interest Measure"
author: "Brandon Foster, Ph.D."
date: "`r format(Sys.time(), '%d %B, %Y, %H:%M')`"
output:
  html_document:
  html_notebook: null
---

# Introduction

The following report outlines exploratory analyses to ascertain the dimensional structure of the Science Interest measure. In the following analyses, sample of 447 students responded to a measure of science interest measure, with items measuring their: desire to do science, career interest in science, and self-concept in science. Confirmatory analyses for a three dimensional structure of the measure failed to produce an adequate fit. As such, in order to determine whether distinctions among the items are justified, an exploratory factor analysis was conducted. 

## Import the data 
Let's bring in the data for analyses, load the necessary packages, load any functions necessary for the analyses, and subset out the items so that they can be used in the subsequent analyses. Please note, that I have chosen to use all of the respondents to the survey, which was administered during the post-science fair exposure period. This is slightly different than the sample we will use to investigate outcomes. I do not expect the factor solutions would look that different if those few students who didn't participate in the science fair were removed from the analyses.

```{r, import, message=FALSE, warning=FALSE, tidy=TRUE}
# load packaes
if (!require("pacman")) install.packages("pacman")
pacman::p_load(MplusAutomation, psych, tidyr, foreign, ggplot2, ggalt, ggthemes, readr, dplyr, knitr, scales, pander, lavaan, kableExtra, GPArotation)

# Import the data ----
joined.dat <- readRDS(file = "../data/joined.dat")

# Load the custom functions ----
source("../functions/functions.r")

# Document options ----
panderOptions('digits', 2)
panderOptions('round', 2)
panderOptions('keep.trailing.zeros', TRUE)

# Munge data ----
items <- joined.dat %>%
  select(s_preInt_Des_15, s_preInt_Des_17, s_preInt_Des_21, s_preInt_Des_24, s_preInt_Des_26, 
         s_preInt_Des_29, s_preInt_Des_33, s_preInt_Car_16, s_preInt_Car_18, s_preInt_Car_20, 
         s_preInt_Car_23, s_preInt_Car_25, s_preInt_Car_28, s_preInt_Car_30, s_preInt_Car_32, 
         s_preInt_Car_34, s_preInt_Car_36, s_preInt_Self_19, s_preInt_Self_22, 
         s_preInt_Self_27, s_preInt_Self_31 ,s_preInt_Self_35)
```

# EFA: Run #1

The following analyses uses an oblique rotation and a principal axis method for extraction. This will produce an [OLS solution which is not as sensitive to improper matrices as is the maximum likelihood method, and will sometimes produce more interpretable results](http://personality-project.org/r/psych/HowTo/factor.pdf). The following analysis utilizes a promax rotation, which is standard for correlated factors. 
```{r, efa.1, message=FALSE, warning=FALSE, tidy=TRUE}
# run the EFA model for each numer of factors. 
efa.2.5.promax <- lapply(2:5, function(x) {fa(items, nfactors=x, fm="pa", rotate = "promax", 
                                              max.iter = 500)})
```

Next, the fit statistics for all four factor models are provided. An easy way to ascertain the best "fitting" model is to look for the model with the lowest BIC. The TLI and RMSEA values can then be used to examine how well that model fit the data. Results indicate that the 2-factor model exhibits the smallest BIC statistic, followed by the 5-factor soultuon. Of these two models, the 5-factor model shows the smallest fit statistics with RMSEA value = about .05, and TLI > .90. This result indicates that the patterns in the factor loadings for both should be examined. 

```{r, efa.1.fit, message=FALSE, warning=FALSE, tidy=TRUE}
tibble(
  "Number of Factors" = c(2, 3, 4, 5),
  "Tucker-Lewis Index (TLI)" = c(efa.2.5.promax[[1]]$TLI, efa.2.5.promax[[2]]$TLI,
                                 efa.2.5.promax[[3]]$TLI, efa.2.5.promax[[4]]$TLI), 
  "RMSEA" = c(efa.2.5.promax[[1]]$RMSEA[1], efa.2.5.promax[[2]]$RMSEA[1], 
              efa.2.5.promax[[3]]$RMSEA[1], efa.2.5.promax[[4]]$RMSEA[1]),
  "Lower 90% RMSEA" = c(efa.2.5.promax[[1]]$RMSEA[2], efa.2.5.promax[[2]]$RMSEA[2], 
                        efa.2.5.promax[[3]]$RMSEA[2], efa.2.5.promax[[4]]$RMSEA[2]),
  "Upper 90% RMSEA" = c(efa.2.5.promax[[1]]$RMSEA[3], efa.2.5.promax[[2]]$RMSEA[3], 
                       efa.2.5.promax[[3]]$RMSEA[3], efa.2.5.promax[[4]]$RMSEA[3]),
  "Bayesian Information Criterion (BIC)" = c(efa.2.5.promax[[1]]$BIC, 
                                             efa.2.5.promax[[2]]$BIC, 
                                             efa.2.5.promax[[3]]$BIC, 
                                             efa.2.5.promax[[4]]$BIC)
  ) %>%
  kable(digits = 3, format="html", caption="Fit statistics for the four different EFA 
          models") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

## 2-factor solution
Now we will take a look at the details for the 2-factor solution. First, let's look at a factor diagram for the 2-factor solution. This can be an easy way to visualize the solution. From a substantive perspective, this solutions is quite intuitive. When inspecting the diagram you can see that the first factor loads onto all of the career interest in science items **and** the desire to do science items. We might expect that the items for these two concepts are highly correlated with one another... that students who have a high desire to do science would most likely indicate that they were interested in a career in science. Said in other words, we would expect the responses to these items to covary. The fact that the first factor loads onto all of these items means that they likely do not differentiate distinctly enough to warrant creating a factor score for each. The second factor captures all of the self-concept items. Further, the factor loadings for the indicators for this factor are all >= .50. In addition, the correlation between the first and second factor is = .60, squarring this value we find that the the shared variance between the factors is 16%, so while there is a relationship between the two factors, each is measuring something distinct. Overall, this is about as clean cut a factor solution as you can find in an exploratory analyses. However, please note that while this solution "makes sense," we still don't have an understanding of how well the items are measuring each factor. We'll need to dig deeper to gain those insights.

```{r, efa.1.2diag, message=FALSE, warning=FALSE, tidy=TRUE, results='asis'}
fa.diagram(efa.2.5.promax[[1]], main="Factor diagram for the 2-factor solution")
```
